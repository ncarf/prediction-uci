{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "#def load_housing_data(housing_path=HOUSING_PATH):\n",
    "#    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "#    return pd.read_csv(csv_path)\n",
    "\n",
    "DATASET_PATH = \"datasets/uci/\"\n",
    "def load_uci_data(path):\n",
    "    csv_path = os.path.join(DATASET_PATH, path)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing = load_housing_data()\n",
    "#housing.head()\n",
    "\n",
    "#Otros candidatos a agregar:\n",
    "\n",
    "# Producto 11: Incidencia por region\n",
    "# https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto11\n",
    "\n",
    "# Producto 26: Casos nuevos con sintomas por region\n",
    "# https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto26\n",
    "\n",
    "# Producto 27: Casos nuevos sin sintomas por region\n",
    "# https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto27\n",
    "\n",
    "# Producto 38: Casos fallecidos por comuna (usar CasosFallecidosPorComuna_std)\n",
    "# https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto38\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "# Producto 8: Pacientes COVID UCI (RM)\n",
    "# https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto8\n",
    "uci_region = load_uci_data(\"UCI_T.csv\")\n",
    "\n",
    "# Producto 19: Casos activos (RM)\n",
    "# https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto19\n",
    "casos_activos = load_uci_data(\"ActivosComuna_std.csv\") #Nuevo\n",
    "\n",
    "# Producto 20: Número de ventiladores\n",
    "# https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto20\n",
    "vent_disp = load_uci_data(\"NumeroVentiladores_T.csv\")\n",
    "\n",
    "# Producto 23: Pacientes críticos\n",
    "# https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto23\n",
    "uci_covid_nacional = load_uci_data(\"PacientesCriticos_T.csv\")\n",
    "\n",
    "# Producto 24: Camas Hospital Diario\n",
    "# https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto24\n",
    "camas = load_uci_data(\"CamasHospital_Diario_T.csv\")\n",
    "\n",
    "# Producto 35: Comorbilidad\n",
    "# https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto35\n",
    "comorb_nacional = load_uci_data(\"Comorbilidad_T.csv\")\n",
    "\n",
    "# Producto 37: Defunciones\n",
    "# https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto37\n",
    "defunc_nacional = load_uci_data(\"Defunciones_T.csv\")\n",
    "\n",
    "# Productos 38: Casos fallecidos por comuna\n",
    "#https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto38\n",
    "defunc_regional = load_uci_data(\"CasosFallecidosComuna_std.csv\")   \n",
    "\n",
    "# Producto 44: Evolución semanal de egresos hospitalarios pacientes COVID-19\n",
    "# https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto44\n",
    "egresos_nacional = load_uci_data(\"Egresos_std.csv\") #Nuevo\n",
    "\n",
    "# Producto 52: Camas Hospital (RM)\n",
    "# https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto52\n",
    "camas_region = load_uci_data(\"CamasHospital_Regional_std.csv\")\n",
    "\n",
    "# Producto 74: Paso a paso\n",
    "# https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto74\n",
    "paso_a_paso = load_uci_data(\"paso_a_paso_T.csv\")\n",
    "\n",
    "# Producto 76: Avance en Campaña de Vacunación COVID-19\n",
    "# https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto76\n",
    "Vacunacion = pd.read_csv(os.path.join(\"datasets/uci/\", \"vacunacion_t.txt\"), sep=\",\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c255ce664d70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatistics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcamas_region\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcamas_region\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcamas_region\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Region\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Metropolitana\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcamas_region\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcamas_region\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Fecha\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Serie\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Fecha\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Serie\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Casos\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcamas_region\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcamas_region\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Fecha'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Serie'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Casos'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3013\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3015\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3017\u001b[0m         \u001b[1;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3068\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3069\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3070\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3072\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3598\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3599\u001b[0m         \"\"\"\n\u001b[1;32m-> 3600\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3601\u001b[0m         \u001b[1;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3602\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3584\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3586\u001b[1;33m         new_data = self._mgr.take(\n\u001b[0m\u001b[0;32m   3587\u001b[0m             \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3588\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[0;32m   1472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1473\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1474\u001b[1;33m         return self.reindex_indexer(\n\u001b[0m\u001b[0;32m   1475\u001b[0m             \u001b[0mnew_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1476\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   1309\u001b[0m             )\n\u001b[0;32m   1310\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1311\u001b[1;33m             new_blocks = [\n\u001b[0m\u001b[0;32m   1312\u001b[0m                 blk.take_nd(\n\u001b[0;32m   1313\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1310\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m             new_blocks = [\n\u001b[1;32m-> 1312\u001b[1;33m                 blk.take_nd(\n\u001b[0m\u001b[0;32m   1313\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m                     \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1402\u001b[0m             \u001b[0mallow_fill\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1404\u001b[1;33m         new_values = algos.take_nd(\n\u001b[0m\u001b[0;32m   1405\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1406\u001b[0m         )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from statistics import mode\n",
    "\n",
    "camas_region = camas_region[camas_region[\"Region\"].str.match(\"Metropolitana\")]\n",
    "camas_region = camas_region.groupby([\"Fecha\", \"Serie\"])[\"Fecha\", \"Serie\", \"Casos\"].sum().reset_index()\n",
    "camas_region = camas_region.pivot_table(index=['Fecha'], columns=['Serie'], values='Casos').fillna(0)\n",
    "#camas_region.set_index(camas_region[\"Fecha\"], inplace=True)\n",
    "#camas_region.drop(axis=1, labels=\"Fecha\", inplace=True)\n",
    "camas_region.drop(axis=1, labels=\"Camas base (2019)\", inplace=True)\n",
    "\n",
    "camas_region.index.name=None\n",
    "\n",
    "#Tenemos tambien las camas nacionales, pero es preferible usar las regionales\n",
    "camas.columns = ['Fecha', 'Camas basicas nac.', 'Camas medias nac.', 'Camas UTI nac.', 'Camas UCI nac.']\n",
    "camas.set_index(camas[\"Fecha\"], drop=True, inplace=True)\n",
    "camas.drop(axis=1, labels=[\"Fecha\"], inplace=True)\n",
    "camas.index.name = None\n",
    "\n",
    "\n",
    "comorb_nacional.drop(comorb_nacional.columns[[*range(1,12)]], axis=1, inplace=True)\n",
    "comorb_nacional.columns = ['Comorbilidad', 'Hipertensión arterial', 'Diabetes', 'Obesidad', 'Asma',\n",
    "       'Enfermedad cardiovascular', 'Enfermedad pulmonar crónica',\n",
    "       'Cardiopatía crónica', 'Enfermedad renal crónica',\n",
    "       'Enfermedad neurológica crónica', 'Inmunocomprometido',\n",
    "       'Enfermedad hepática crónica']\n",
    "comorb_nacional.drop([0],axis=0, inplace=True)\n",
    "comorb_nacional.set_index(comorb_nacional[\"Comorbilidad\"], drop=True, inplace=True)\n",
    "comorb_nacional.drop(axis=1, labels=[\"Comorbilidad\"], inplace=True)\n",
    "comorb_nacional.index.name = None\n",
    "\n",
    "defunc_nacional = defunc_nacional[[\"Fecha\",\"Defunciones_2020-07-16\"]]\n",
    "defunc_nacional.columns = [\"Fecha\", \"Defunciones nacional\"]\n",
    "defunc_nacional.set_index(defunc_nacional[\"Fecha\"], inplace=True)\n",
    "defunc_nacional.drop(axis=1, labels=\"Fecha\", inplace=True)\n",
    "defunc_nacional.index.name = None\n",
    "\n",
    "defunc_regional = defunc_regional[4:]\n",
    "defunc_regional.set_index(defunc_regional[\"Region\"], inplace=True)\n",
    "defunc_regional = defunc_regional.iloc[:,95:148]\n",
    "defunc_regional = defunc_regional.apply(pd.to_numeric)\n",
    "defunc_regional[\"Defunciones regional\"] = defunc_regional.sum(axis=1,numeric_only=True)\n",
    "defunc_regional.index.name = None\n",
    "defunc_regional = defunc_regional[\"Defunciones regional\"]\n",
    "\n",
    "vent_disp.columns = [\"Fecha\", \"Total vent.\", \"Vent. ocupados\", \"Vent. disponibles\"]\n",
    "vent_disp.set_index(vent_disp[\"Fecha\"], inplace=True)\n",
    "vent_disp.drop(axis=1, labels=\"Fecha\", inplace=True)\n",
    "vent_disp.index.name = None\n",
    "\n",
    "uci_covid_nacional.columns = [\"Fecha\", \"Pac. criticos nacional\"]\n",
    "uci_covid_nacional.set_index(uci_covid_nacional[\"Fecha\"], inplace=True)\n",
    "uci_covid_nacional.drop(axis=1, labels=\"Fecha\", inplace=True)\n",
    "uci_covid_nacional.index.name = None\n",
    "\n",
    "uci_region = uci_region[[\"Region\", \"Metropolitana\"]]\n",
    "uci_region.columns = [\"Fecha\", \"Casos diarios region\"]\n",
    "uci_region.drop([0,1],axis=0, inplace=True)\n",
    "uci_region.set_index(uci_region[\"Fecha\"], inplace=True)\n",
    "uci_region.drop(axis=1, labels=\"Fecha\", inplace=True)\n",
    "uci_region.index.name = None\n",
    "\n",
    "#casos_activos = casos_activos.rename(columns = {'Casos activos':'Casos activos region'})\n",
    "casos_activos = casos_activos.loc[:,[\"Region\", \"Fecha\", \"Casos activos\"]]\n",
    "casos_activos.columns = [\"Region\", \"Fecha\", \"Casos activos region\"]\n",
    "casos_activos = casos_activos[casos_activos[\"Region\"].str.match(\"Metropolitana\")]\n",
    "casos_activos = casos_activos.groupby(\"Fecha\")[\"Fecha\", \"Casos activos region\"].sum().reset_index()\n",
    "casos_activos.set_index(casos_activos[\"Fecha\"], inplace=True)\n",
    "casos_activos.drop(axis=1, labels=\"Fecha\", inplace=True)\n",
    "casos_activos.index.name=None\n",
    "\n",
    "#paso_a_paso = paso_a_paso.iloc[4:,:]\n",
    "#paso_a_paso.set_index(paso_a_paso[\"codigo_region\"], drop=True, inplace=True)\n",
    "#paso_a_paso.drop(axis=1, labels=[\"codigo_region\"], inplace=True)\n",
    "#paso_a_paso.index.name = None\n",
    "#moda = [mode(paso_a_paso.iloc[i,:]) for i in range(paso_a_paso.shape[0])]\n",
    "#moda = np.asarray(moda)\n",
    "#paso_a_paso[\"Paso a paso\"] = moda\n",
    "#paso_a_paso = pd.to_numeric(paso_a_paso.iloc[:,-1], downcast='float')\n",
    "\n",
    "# Este requiere tratamiento\n",
    "#egresos_nacional = egresos_nacional[[\"Fecha Publicación\", \"Egresos\"]]\n",
    "#egresos_nacional.set_index(egresos_nacional[\"Fecha Publicación\"],inplace=True)\n",
    "#egresos_nacional.drop(axis=1, labels=\"Fecha Publicación\", inplace=True)\n",
    "#egresos_nacional.index.name = None\n",
    "\n",
    "\n",
    "\n",
    "#camas.set_index(camas[\"Tipo de cama\"], drop=True)\n",
    "#amas.drop(axis=1, labels=[\"Tipo de cama\"])\n",
    "\n",
    "#amas.set_index(camas[\"Tipo de cama\"], drop=True)\n",
    "#amas.drop(axis=1, labels=[\"Tipo de cama\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTE\n",
    "paso_a_paso = paso_a_paso.drop([1,2,3])\n",
    "paso_a_paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTE\n",
    "\n",
    "paso_a_paso.set_index(\"codigo_region\", drop=True, inplace=True)\n",
    "paso_a_paso.index.name = \"Fecha\"\n",
    "\n",
    "#paso_a_paso1.drop([\"codigo_region\"], axis=1)\n",
    "paso_a_paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTE\n",
    "i=0\n",
    "modaArica = []\n",
    "modaTarapaca = []\n",
    "modaAntofagasta = []\n",
    "modaAtacama = []\n",
    "modaCoquimbo = []\n",
    "modaValparaiso = []\n",
    "modaMetropolitana = []\n",
    "modaOHiggins = []\n",
    "modaMaule = []\n",
    "modaNuble = []\n",
    "modaBiobio = []\n",
    "modaAraucania = []\n",
    "modaLosRios = []\n",
    "modaLosLagos = []\n",
    "modaAysen = []\n",
    "modaMagallanes = []\n",
    "\n",
    "while(i<len(paso_a_paso)):\n",
    "    modaArica.append(mode(paso_a_paso[[\"15\", \"15.1\", \"15.2\", \"15.3\", \"15.4\"]].iloc[i,:]))\n",
    "    modaTarapaca.append(mode(paso_a_paso[[\"1\", \"1.1\", \"1.2\", \"1.3\", \"1.4\", \"1.5\", \"1.6\", \"1.7\"]].iloc[i,:]))\n",
    "    modaAntofagasta.append(mode(paso_a_paso[[\"2\",\"2.1\",\"2.2\",\"2.3\",\"2.4\",\"2.5\",\"2.6\",\"2.7\",\"2.8\",\"2.9\",\"2.10\",\"2.11\"]].iloc[i,:]))\n",
    "    modaAtacama.append(mode(paso_a_paso[[\"3\",\"3.1\",\"3.2\",\"3.3\",\"3.4\",\"3.5\",\"3.6\",\"3.7\",\"3.8\"]].iloc[i,:]))\n",
    "    modaCoquimbo.append(mode(paso_a_paso[[\"4\",\"4.1\",\"4.2\",\"4.3\",\"4.4\",\"4.5\",\"4.6\",\"4.7\",\"4.8\",\"4.9\",\"4.10\",\"4.11\",\"4.12\",\"4.13\",\"4.14\"]].iloc[i,:]))\n",
    "    modaValparaiso.append(mode(paso_a_paso[[\"5\",\"5.1\",\"5.2\",\"5.3\",\"5.4\",\"5.5\",\"5.6\",\"5.7\",\"5.8\",\"5.9\",\"5.10\",\"5.11\",\"5.12\",\"5.13\",\"5.14\",\"5.15\",\"5.16\",\"5.17\",\"5.18\",\"5.19\",\"5.20\",\"5.21\",\"5.22\",\"5.23\",\"5.24\",\"5.25\",\"5.26\",\"5.27\",\"5.28\",\"5.29\",\"5.30\",\"5.31\",\"5.32\",\"5.33\",\"5.34\",\"5.35\",\"5.36\",\"5.37\"]].iloc[i,:]))\n",
    "    modaMetropolitana.append(mode(paso_a_paso[[\"13\",\"13.1\",\"13.2\",\"13.3\",\"13.4\",\"13.5\",\"13.6\",\"13.7\",\"13.8\",\"13.9\",\"13.10\",\"13.11\",\"13.12\",\"13.13\",\"13.14\",\"13.15\",\"13.16\",\"13.17\",\"13.18\",\"13.19\",\"13.20\",\"13.21\",\"13.22\",\"13.23\",\"13.24\",\"13.25\",\"13.26\",\"13.27\",\"13.28\",\"13.29\",\"13.30\",\"13.31\",\"13.32\",\"13.33\",\"13.34\",\"13.35\",\"13.36\",\"13.37\",\"13.38\",\"13.39\",\"13.40\",\"13.41\",\"13.42\",\"13.43\",\"13.44\",\"13.45\",\"13.46\",\"13.47\",\"13.48\",\"13.49\",\"13.50\",\"13.51\",\"13.52\",\"13.53\",\"13.54\"]].iloc[i,:]))\n",
    "    modaOHiggins.append(mode(paso_a_paso[[\"6\",\"6.1\",\"6.2\",\"6.3\",\"6.4\",\"6.5\",\"6.6\",\"6.7\",\"6.8\",\"6.9\",\"6.10\",\"6.11\",\"6.12\",\"6.13\",\"6.14\",\"6.15\",\"6.16\",\"6.17\",\"6.18\",\"6.19\",\"6.20\",\"6.21\",\"6.22\",\"6.23\",\"6.24\",\"6.25\",\"6.26\",\"6.27\",\"6.28\",\"6.29\",\"6.30\",\"6.31\",\"6.32\"]].iloc[i,:]))\n",
    "    modaMaule.append(mode(paso_a_paso[[\"7\",\"7.1\",\"7.2\",\"7.3\",\"7.4\",\"7.5\",\"7.6\",\"7.7\",\"7.8\",\"7.9\",\"7.10\",\"7.11\",\"7.12\",\"7.13\",\"7.14\",\"7.15\",\"7.16\",\"7.17\",\"7.18\",\"7.19\",\"7.20\",\"7.21\",\"7.22\",\"7.23\",\"7.24\",\"7.25\",\"7.26\",\"7.27\",\"7.28\",\"7.29\",\"7.30\",\"7.31\",\"7.32\",\"7.33\"]].iloc[i,:]))\n",
    "    modaNuble.append(mode(paso_a_paso[[\"16\",\"16.1\",\"16.2\",\"16.3\",\"16.4\",\"16.5\",\"16.6\",\"16.7\",\"16.8\",\"16.9\",\"16.10\",\"16.11\",\"16.12\",\"16.13\",\"16.14\",\"16.15\",\"16.16\",\"16.17\",\"16.18\",\"16.19\",\"16.20\",\"16.21\",\"16.22\"]].iloc[i,:]))\n",
    "    modaBiobio.append(mode(paso_a_paso[[\"8\",\"8.1\",\"8.2\",\"8.3\",\"8.4\",\"8.5\",\"8.6\",\"8.7\",\"8.8\",\"8.9\",\"8.10\",\"8.11\",\"8.12\",\"8.13\",\"8.14\",\"8.15\",\"8.16\",\"8.17\",\"8.18\",\"8.19\",\"8.20\",\"8.21\",\"8.22\",\"8.23\",\"8.24\",\"8.25\",\"8.26\",\"8.27\",\"8.28\",\"8.29\",\"8.30\",\"8.31\",\"8.32\",\"8.33\",\"8.34\"]].iloc[i,:]))\n",
    "    modaAraucania.append(mode(paso_a_paso[[\"9\",\"9.1\",\"9.2\",\"9.3\",\"9.4\",\"9.5\",\"9.6\",\"9.7\",\"9.8\",\"9.9\",\"9.10\",\"9.11\",\"9.12\",\"9.13\",\"9.14\",\"9.15\",\"9.16\",\"9.17\",\"9.18\",\"9.19\",\"9.20\",\"9.21\",\"9.22\",\"9.23\",\"9.24\",\"9.25\",\"9.26\",\"9.27\",\"9.28\",\"9.29\",\"9.30\",\"9.31\",\"9.32\",\"9.33\",\"9.34\",\"9.35\"]].iloc[i,:]))\n",
    "    modaLosRios.append(mode(paso_a_paso[[\"14\",\"14.1\",\"14.2\",\"14.3\",\"14.4\",\"14.5\",\"14.6\",\"14.7\",\"14.8\",\"14.9\",\"14.10\",\"14.11\",\"14.12\"]].iloc[i,:]))\n",
    "    modaLosLagos.append(mode(paso_a_paso[[\"10\",\"10.1\",\"10.2\",\"10.3\",\"10.4\",\"10.5\",\"10.6\",\"10.7\",\"10.8\",\"10.9\",\"10.10\",\"10.11\",\"10.12\",\"10.13\",\"10.14\",\"10.15\",\"10.16\",\"10.17\",\"10.18\",\"10.19\",\"10.20\",\"10.21\",\"10.22\",\"10.23\",\"10.24\",\"10.25\",\"10.26\",\"10.27\",\"10.28\",\"10.29\",\"10.30\",\"10.31\",\"10.32\",\"10.33\",\"10.34\",\"10.35\",\"10.36\",\"10.37\"]].iloc[i,:]))\n",
    "    modaAysen.append(mode(paso_a_paso[[\"11\",\"11.1\",\"11.2\",\"11.3\",\"11.4\",\"11.5\",\"11.6\",\"11.7\",\"11.8\",\"11.9\",\"11.10\",\"11.11\",\"11.12\",\"11.13\",\"11.14\",\"11.15\",\"11.16\",\"11.17\",\"11.18\",\"11.19\"]].iloc[i,:]))\n",
    "    modaMagallanes.append(mode(paso_a_paso[[\"12\",\"12.1\",\"12.2\",\"12.3\",\"12.4\",\"12.5\",\"12.6\",\"12.7\",\"12.8\",\"12.9\",\"12.10\",\"12.11\"]].iloc[i,:]))\n",
    "    i = i+1   \n",
    "\n",
    "paso_a_paso[\"Arica y Parinacota\"] = modaArica\n",
    "paso_a_paso[\"Tarapacá\"] = modaTarapaca\n",
    "paso_a_paso[\"Antofagasta\"] = modaAntofagasta\n",
    "paso_a_paso[\"Atacama\"] = modaAtacama\n",
    "paso_a_paso[\"Coquimbo\"] = modaCoquimbo\n",
    "paso_a_paso[\"Valparaíso\"] = modaValparaiso\n",
    "paso_a_paso[\"Metropolitana\"] = modaMetropolitana\n",
    "paso_a_paso[\"O'Higgins\"] = modaOHiggins\n",
    "paso_a_paso[\"Maule\"] = modaMaule\n",
    "paso_a_paso[\"Nuble\"] = modaNuble\n",
    "paso_a_paso[\"Biobío\"] = modaBiobio\n",
    "paso_a_paso[\"Araucania\"] = modaAraucania\n",
    "paso_a_paso[\"Los Rios\"] = modaLosRios\n",
    "paso_a_paso[\"Los Lagos\"] = modaLosLagos\n",
    "paso_a_paso[\"Aysén\"] = modaAysen\n",
    "paso_a_paso[\"Magallanes\"] = modaMagallanes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTE\n",
    "paso_a_paso = paso_a_paso.drop(columns=[\"15\", \"15.1\", \"15.2\", \"15.3\", \"15.4\",\n",
    "                            \"1\", \"1.1\", \"1.2\", \"1.3\", \"1.4\", \"1.5\", \"1.6\", \"1.7\",\n",
    "                            \"2\",\"2.1\",\"2.2\",\"2.3\",\"2.4\",\"2.5\",\"2.6\",\"2.7\",\"2.8\",\"2.9\",\"2.10\",\"2.11\",\n",
    "                            \"3\",\"3.1\",\"3.2\",\"3.3\",\"3.4\",\"3.5\",\"3.6\",\"3.7\",\"3.8\",\n",
    "                            \"4\",\"4.1\",\"4.2\",\"4.3\",\"4.4\",\"4.5\",\"4.6\",\"4.7\",\"4.8\",\"4.9\",\"4.10\",\"4.11\",\"4.12\",\"4.13\",\"4.14\",\n",
    "                            \"5\",\"5.1\",\"5.2\",\"5.3\",\"5.4\",\"5.5\",\"5.6\",\"5.7\",\"5.8\",\"5.9\",\"5.10\",\"5.11\",\"5.12\",\"5.13\",\"5.14\",\"5.15\",\"5.16\",\"5.17\",\"5.18\",\"5.19\",\"5.20\",\"5.21\",\"5.22\",\"5.23\",\"5.24\",\"5.25\",\"5.26\",\"5.27\",\"5.28\",\"5.29\",\"5.30\",\"5.31\",\"5.32\",\"5.33\",\"5.34\",\"5.35\",\"5.36\",\"5.37\",\n",
    "                            \"13\",\"13.1\",\"13.2\",\"13.3\",\"13.4\",\"13.5\",\"13.6\",\"13.7\",\"13.8\",\"13.9\",\"13.10\",\"13.11\",\"13.12\",\"13.13\",\"13.14\",\"13.15\",\"13.16\",\"13.17\",\"13.18\",\"13.19\",\"13.20\",\"13.21\",\"13.22\",\"13.23\",\"13.24\",\"13.25\",\"13.26\",\"13.27\",\"13.28\",\"13.29\",\"13.30\",\"13.31\",\"13.32\",\"13.33\",\"13.34\",\"13.35\",\"13.36\",\"13.37\",\"13.38\",\"13.39\",\"13.40\",\"13.41\",\"13.42\",\"13.43\",\"13.44\",\"13.45\",\"13.46\",\"13.47\",\"13.48\",\"13.49\",\"13.50\",\"13.51\",\"13.52\",\"13.53\",\"13.54\",\n",
    "                            \"6\",\"6.1\",\"6.2\",\"6.3\",\"6.4\",\"6.5\",\"6.6\",\"6.7\",\"6.8\",\"6.9\",\"6.10\",\"6.11\",\"6.12\",\"6.13\",\"6.14\",\"6.15\",\"6.16\",\"6.17\",\"6.18\",\"6.19\",\"6.20\",\"6.21\",\"6.22\",\"6.23\",\"6.24\",\"6.25\",\"6.26\",\"6.27\",\"6.28\",\"6.29\",\"6.30\",\"6.31\",\"6.32\",\n",
    "                            \"7\",\"7.1\",\"7.2\",\"7.3\",\"7.4\",\"7.5\",\"7.6\",\"7.7\",\"7.8\",\"7.9\",\"7.10\",\"7.11\",\"7.12\",\"7.13\",\"7.14\",\"7.15\",\"7.16\",\"7.17\",\"7.18\",\"7.19\",\"7.20\",\"7.21\",\"7.22\",\"7.23\",\"7.24\",\"7.25\",\"7.26\",\"7.27\",\"7.28\",\"7.29\",\"7.30\",\"7.31\",\"7.32\",\"7.33\",\n",
    "                            \"16\",\"16.1\",\"16.2\",\"16.3\",\"16.4\",\"16.5\",\"16.6\",\"16.7\",\"16.8\",\"16.9\",\"16.10\",\"16.11\",\"16.12\",\"16.13\",\"16.14\",\"16.15\",\"16.16\",\"16.17\",\"16.18\",\"16.19\",\"16.20\",\"16.21\",\"16.22\",\n",
    "                            \"8\",\"8.1\",\"8.2\",\"8.3\",\"8.4\",\"8.5\",\"8.6\",\"8.7\",\"8.8\",\"8.9\",\"8.10\",\"8.11\",\"8.12\",\"8.13\",\"8.14\",\"8.15\",\"8.16\",\"8.17\",\"8.18\",\"8.19\",\"8.20\",\"8.21\",\"8.22\",\"8.23\",\"8.24\",\"8.25\",\"8.26\",\"8.27\",\"8.28\",\"8.29\",\"8.30\",\"8.31\",\"8.32\",\"8.33\",\"8.34\",\n",
    "                            \"9\",\"9.1\",\"9.2\",\"9.3\",\"9.4\",\"9.5\",\"9.6\",\"9.7\",\"9.8\",\"9.9\",\"9.10\",\"9.11\",\"9.12\",\"9.13\",\"9.14\",\"9.15\",\"9.16\",\"9.17\",\"9.18\",\"9.19\",\"9.20\",\"9.21\",\"9.22\",\"9.23\",\"9.24\",\"9.25\",\"9.26\",\"9.27\",\"9.28\",\"9.29\",\"9.30\",\"9.31\",\"9.32\",\"9.33\",\"9.34\",\"9.35\",\n",
    "                            \"14\",\"14.1\",\"14.2\",\"14.3\",\"14.4\",\"14.5\",\"14.6\",\"14.7\",\"14.8\",\"14.9\",\"14.10\",\"14.11\",\"14.12\",\n",
    "                            \"10\",\"10.1\",\"10.2\",\"10.3\",\"10.4\",\"10.5\",\"10.6\",\"10.7\",\"10.8\",\"10.9\",\"10.10\",\"10.11\",\"10.12\",\"10.13\",\"10.14\",\"10.15\",\"10.16\",\"10.17\",\"10.18\",\"10.19\",\"10.20\",\"10.21\",\"10.22\",\"10.23\",\"10.24\",\"10.25\",\"10.26\",\"10.27\",\"10.28\",\"10.29\",\"10.30\",\"10.31\",\"10.32\",\"10.33\",\"10.34\",\"10.35\",\"10.36\",\"10.37\",\n",
    "                            \"11\",\"11.1\",\"11.2\",\"11.3\",\"11.4\",\"11.5\",\"11.6\",\"11.7\",\"11.8\",\"11.9\",\"11.10\",\"11.11\",\"11.12\",\"11.13\",\"11.14\",\"11.15\",\"11.16\",\"11.17\",\"11.18\",\"11.19\",\n",
    "                            \"12\",\"12.1\",\"12.2\",\"12.3\",\"12.4\",\"12.5\",\"12.6\",\"12.7\",\"12.8\",\"12.9\",\"12.10\",\"12.11\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTE\n",
    "paso_a_paso = paso_a_paso.drop([\"region_residencia\"])\n",
    "\n",
    "#paso_a_paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTE\n",
    "i=0\n",
    "j=0\n",
    "\n",
    "while(i < len(paso_a_paso)):\n",
    "    while(j<len(paso_a_paso.columns)):\n",
    "        if(paso_a_paso.iloc[i,j] == '1'):\n",
    "             paso_a_paso.iloc[i,j] = 0.98\n",
    "        if(paso_a_paso.iloc[i,j] == '2'):\n",
    "            paso_a_paso.iloc[i,j] = 0.45\n",
    "        if(paso_a_paso.iloc[i,j] == '3'):\n",
    "            paso_a_paso.iloc[i,j] = 0.25\n",
    "        if(paso_a_paso.iloc[i,j] == '4'):\n",
    "            paso_a_paso.iloc[i,j] = 0.25\n",
    "        if(paso_a_paso.iloc[i,j] == '5'):\n",
    "            paso_a_paso.iloc[i,j] = 0.25\n",
    "        j=j+1\n",
    "    i=i+1\n",
    "    j=0\n",
    "\n",
    "paso_a_paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTE\n",
    "paso_a_paso[\"Promedio nacional de encierro\"] = paso_a_paso.mean(axis=1)\n",
    "#while(i<len(paso_a_paso)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTE\n",
    "paso_a_paso = paso_a_paso[[\"Promedio nacional de encierro\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paso_a_paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ajuste de datos de vacunacion\n",
    "Vacunacion = Vacunacion[[0, 1, 2, 3]]\n",
    "Vacunacion.columns = [\"Fecha\", \"Primera_V\", \"Segunda_V\", \"V_Unica\"]\n",
    "Vacunacion = Vacunacion.drop([0,1])\n",
    "Vacunacion.set_index(\"Fecha\", drop=True, inplace=True)\n",
    "\n",
    "i=0\n",
    "anterior = 0\n",
    "tmp_list = []\n",
    "while(i < len(Vacunacion)):\n",
    "    tmp_list.append(int(float(Vacunacion[\"Primera_V\"][i])) - anterior)\n",
    "    anterior = int(float(Vacunacion[\"Primera_V\"][i]))\n",
    "    i=i+1\n",
    "\n",
    "Vacunacion[\"Primera_V_Daily\"] = tmp_list\n",
    "\n",
    "i=0\n",
    "anterior = 0\n",
    "tmp_list = []\n",
    "while(i < len(Vacunacion)):\n",
    "    tmp_list.append(int(float(Vacunacion[\"Segunda_V\"][i])) - anterior)\n",
    "    anterior = int(float(Vacunacion[\"Segunda_V\"][i]))\n",
    "    i=i+1\n",
    "    \n",
    "Vacunacion[\"Segunda_V_Daily\"] = tmp_list\n",
    "\n",
    "i=0\n",
    "anterior = 0\n",
    "tmp_list = []\n",
    "while(i < len(Vacunacion)):\n",
    "    tmp_list.append(int(float(Vacunacion[\"V_Unica\"][i])) - anterior)\n",
    "    anterior = int(float(Vacunacion[\"V_Unica\"][i]))\n",
    "    i=i+1\n",
    "    \n",
    "Vacunacion[\"V_Unica_Daily\"] = tmp_list\n",
    "Vacunacion = Vacunacion[[\"Primera_V_Daily\", \"Segunda_V_Daily\", \"V_Unica_Daily\"]]\n",
    "Vacunacion.columns = [\"Primera_V\", \"Segunda_V\", \"V_Unica\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comorb_nacional.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTE\n",
    "data = pd.merge(camas, comorb_nacional, how='outer',left_index=True, right_index=True)\n",
    "data = pd.merge(data, camas_region, how='outer', left_index=True, right_index=True)\n",
    "data = pd.merge(data, defunc_nacional,how='outer',left_index=True, right_index=True)\n",
    "data = pd.merge(data, defunc_regional,how='outer',left_index=True, right_index=True)\n",
    "data = pd.merge(data, vent_disp,how='outer', left_index=True, right_index=True)\n",
    "data = pd.merge(data, uci_covid_nacional,how='outer', left_index=True, right_index=True)\n",
    "data = pd.merge(data, uci_region,how='outer', left_index=True, right_index=True)\n",
    "data = pd.merge(data, casos_activos,how='outer', left_index=True, right_index=True)\n",
    "data = pd.merge(data, paso_a_paso,how='outer', left_index=True, right_index=True)\n",
    "data = pd.merge(data, Vacunacion,how='outer', left_index=True, right_index=True)\n",
    "\n",
    "data = data.loc['2020-04-14':]\n",
    "data.index = pd.to_datetime(data.index)\n",
    "for col in data:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTE\n",
    "i=0\n",
    "while(i < len(data)):\n",
    "    if(data[[\"Promedio nacional de encierro\"]].isnull().iloc[i,0]):\n",
    "        data[\"Promedio nacional de encierro\"][i] = 0\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp_data = data[[\"Primera_V\", \"Segunda_V\", \"V_Unica\"]].loc[data[\"Primera_V\"].isnull()].replace(to_replace = np.nan, value = 0, inplace = True)\n",
    "#tmp_data.append(data[[\"Primera_V\", \"Segunda_V\", \"V_Unica\"]].loc[not data[\"Primera_V\"].isnull()])\n",
    "#data\n",
    "\n",
    "#data[[\"Primera_V\", \"Segunda_V\", \"V_Unica\"]][~data[\"Primera_V\"].isnull()]\n",
    "i=0\n",
    "while(i < len(data)):\n",
    "    if(data[[\"Primera_V\"]].isnull().iloc[i,0]):\n",
    "        data[\"Primera_V\"][i] = 0\n",
    "        data[\"Segunda_V\"][i] = 0\n",
    "        data[\"V_Unica\"][i] = 0\n",
    "    i = i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#uci_region\n",
    "# VER UMBRAL y proporción de NaNs\n",
    "#data.columns\n",
    "data_rows = data.shape[0]\n",
    "nan_proportions = data.apply(lambda x: x.isnull().sum() / data_rows, axis=0).to_frame()\n",
    "#nan_proportions\n",
    "data_non_imputable = nan_proportions.loc[nan_proportions[0] >= 0.15]\n",
    "data_non_imputable\n",
    "#type(nan_proportions)\n",
    "\n",
    "#data1.apply(lambda x: x.interpolate())\n",
    "\n",
    "# Hacer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputable = nan_proportions.loc[nan_proportions[0] <= 0.15]\n",
    "inputable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data = data.assign(Hipertensión_arterial_interp=data[\"Hipertensión arterial\"].interpolate(method='spline', order=3, inplace=True))\n",
    "\n",
    "#Columnas con <15% casos faltantes\n",
    "data[\"Camas basicas nac.\"].interpolate(method='spline', order=2, inplace=True)\n",
    "data[\"Camas medias nac.\"].interpolate(method='spline', order=2, inplace=True)\n",
    "data[\"Camas UTI nac.\"].interpolate(method='spline', order=2, inplace=True)\n",
    "data[\"Camas UCI nac.\"].interpolate(method='spline', order=2, inplace=True)\n",
    "data[\"Camas UCI habilitadas\"].interpolate(method='spline', order=2, inplace=True)\n",
    "data[\"Camas UCI ocupadas COVID-19\"].interpolate(method='spline', order=2, inplace=True)\n",
    "data[\"Camas UCI ocupadas no COVID-19\"].interpolate(method='spline', order=2, inplace=True)\n",
    "\n",
    "#Columnas con >15% casos faltantes\n",
    "data[\"Pac. criticos nacional\"].rolling(24, min_periods=1,).median()\n",
    "data[\"Hipertensión arterial\"].interpolate(method='linear', inplace=True)\n",
    "data[\"Diabetes\"].interpolate(method='linear', inplace=True)\n",
    "data[\"Obesidad\"].interpolate(method='linear', inplace=True)\n",
    "data[\"Asma\"].interpolate(method='linear', inplace=True)\n",
    "data[\"Enfermedad cardiovascular\"].interpolate(method='linear', inplace=True)\n",
    "data[\"Enfermedad pulmonar crónica\"].interpolate(method='linear', inplace=True)\n",
    "data[\"Cardiopatía crónica\"].interpolate(method='linear', inplace=True)\n",
    "data[\"Enfermedad renal crónica\"].interpolate(method='linear', inplace=True)\n",
    "data[\"Enfermedad neurológica crónica\"].interpolate(method='linear', inplace=True)\n",
    "data[\"Inmunocomprometido\"].interpolate(method='linear', inplace=True)\n",
    "data[\"Enfermedad hepática crónica\"].interpolate(method='linear', inplace=True)\n",
    "data[\"Defunciones nacional\"].rolling(24, min_periods=1,).median()\n",
    "data[\"Defunciones regional\"].interpolate(method='linear', inplace=True)\n",
    "data[\"Casos activos region\"].interpolate(method='spline', order=3, inplace=True)\n",
    "\n",
    "#data[\"Pac. criticos nacional\"].interpolate(method='time', inplace=True)\n",
    "#data[\"Hipertensión arterial\"].interpolate(method='time', inplace=True)\n",
    "#data[\"Diabetes\"].interpolate(method='time', inplace=True)\n",
    "#data[\"Obesidad\"].interpolate(method='time', inplace=True)\n",
    "#data[\"Asma\"].interpolate(method='time', inplace=True)\n",
    "#data[\"Enfermedad cardiovascular\"].interpolate(method='time', inplace=True)\n",
    "#data[\"Enfermedad pulmonar crónica\"].interpolate(method='time', inplace=True)\n",
    "#data[\"Cardiopatía crónica\"].interpolate(method='time', inplace=True)\n",
    "#data[\"Enfermedad renal crónica\"].interpolate(method='time', inplace=True)\n",
    "#data[\"Enfermedad neurológica crónica\"].interpolate(method='time', inplace=True)\n",
    "#data[\"Inmunocomprometido\"].interpolate(method='time', inplace=True)\n",
    "#data[\"Enfermedad hepática crónica\"].interpolate(method='time', inplace=True)\n",
    "#data[\"Defunciones nacional\"].interpolate(method='time', inplace=True)\n",
    "#data[\"Casos activos region\"].interpolate(method='time', inplace=True)\n",
    "\n",
    "#for col in list(inputable.index):\n",
    "#    print(col)\n",
    "#    data = inputData(col, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.apply(lambda x: x.isnull().sum() / data_rows, axis=0).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc['2020-06-12':'2021-06-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTE\n",
    "data.iloc[:,26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1)\n",
    "ax1.plot(data.iloc[:,[27, 28, 29]])\n",
    "ax1.legend(('Primera dosis', 'Segunda Dosis', 'Dosis unica'), fontsize=15 , loc=4)\n",
    "plt.title(\"Vacunas\", fontsize=30)\n",
    "plt.xlabel(\"Fecha\", fontsize=16)\n",
    "plt.ylabel(\"Cantidad de vacunados\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1)\n",
    "ax1.plot(data.iloc[:,[0,1,2,3]])\n",
    "ax1.legend(('Camas basicas nac.', 'Camas medias nac.', 'Camas UTI nac.',\n",
    "       'Camas UCI nac.'), fontsize=15 , loc=4)\n",
    "plt.title(\"Camas nacionales\", fontsize=30)\n",
    "plt.xlabel(\"Fecha\", fontsize=16)\n",
    "plt.ylabel(\"Cantidad camas\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ESTE\n",
    "fig, ax2 = plt.subplots(1, 1)\n",
    "plot = ax2.plot(data.iloc[:,[15,16,17,23]])\n",
    "ax2.legend(('Camas UCI habilitadas',\n",
    "       'Camas UCI ocupadas COVID-19', 'Camas UCI ocupadas no COVID-19', 'Pac. críticos nacionales'), fontsize=15)\n",
    "ax5 = ax2.twinx()\n",
    "pasos_plot = ax5.plot(data.iloc[:,26], color=\"red\")\n",
    "ax5.set_yticks([1])\n",
    "plt.ylabel(\"Paso a paso (% de encierro)\", fontsize=16)\n",
    "plot = plot + pasos_plot\n",
    "plt.title(\"Camas UCI nacional\", fontsize=30)\n",
    "plt.xlabel(\"Fecha\", fontsize=16)\n",
    "plt.ylabel(\"Cantidad camas\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax3 = plt.subplots(1, 1)\n",
    "ax3.plot(data.iloc[:,[4,5,6,7,8,9,10,11,12,13,14]])\n",
    "ax3.legend(('Hipertensión arterial', 'Diabetes', 'Obesidad',\n",
    "       'Asma', 'Enfermedad cardiovascular', 'Enfermedad pulmonar crónica',\n",
    "       'Cardiopatía crónica', 'Enfermedad renal crónica',\n",
    "       'Enfermedad neurológica crónica','Inmunocomprometido',\n",
    "       'Enfermedad hepática crónica'))\n",
    "plt.yscale('log')\n",
    "plt.title(\"Enfermedades\", fontsize=30)\n",
    "plt.xlabel(\"Fecha\", fontsize=16)\n",
    "plt.ylabel(\"Personas con comorbilidad\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ESTE\n",
    "fig, ax4 = plt.subplots(1, 1)\n",
    "ventiladores_plot = ax4.plot(data.iloc[:,[20,21,22]])\n",
    "#ax4.legend(('Total vent.', 'Vent. ocupados',\n",
    "       #'Vent. disponibles'), fontsize=15)\n",
    "plt.title(\"Ventiladores mecánicos\", fontsize=30)\n",
    "plt.xlabel(\"Fecha\", fontsize=16)\n",
    "plt.ylabel(\"Cantidad ventiladores\", fontsize=16)\n",
    "ax5 = ax4.twinx()\n",
    "pasos_plot = ax5.plot(data.iloc[:,26], color=\"red\")\n",
    "ax5.set_yticks([1])\n",
    "plt.ylabel(\"Paso a paso (% de encierro)\", fontsize=16)\n",
    "#ax5.set_ytickslabels((\"Paso 1\", \"Paso 2\", \"Paso 3\", \"Paso 4\"))\n",
    "plot = ventiladores_plot + pasos_plot\n",
    "ax4.legend(plot, [\"Total vent.\", \"Vent. ocupados\", \"Vent. disponibles\", \"Paso a paso\"], fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax5 = plt.subplots(1, 1)\n",
    "diarios_plot = ax5.plot(data.iloc[:,24])\n",
    "plt.title(\"Casos COVID-19 Región Metropolitana\", fontsize=30)\n",
    "plt.xlabel(\"Fecha\", fontsize=16)\n",
    "plt.ylabel(\"Casos diarios\", fontsize=16)\n",
    "ax6 = ax5.twinx()\n",
    "activos_plot = ax6.plot(data.iloc[:,25], color=\"green\")\n",
    "plot = diarios_plot + activos_plot\n",
    "ax5.legend(plot, [\"Casos diario región\", \"Casos activos región\"], fontsize=15, loc=4)\n",
    "plt.ylabel(\"Casos activos\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax7 = plt.subplots(1, 1)\n",
    "defunciones_plot = ax7.plot(data.iloc[:,[18,19]])\n",
    "#ax7.legend(('Defunciones', 'Vent. ocupados'), fontsize=15)\n",
    "plt.title(\"Ventiladores ocupados en base a defunciones\", fontsize=30)\n",
    "plt.xlabel(\"Fecha\", fontsize=16)\n",
    "plt.ylabel(\"Cantidad defunciones\", fontsize=16)\n",
    "ax8 = ax7.twinx()\n",
    "ventiladores_plot = ax8.plot(data.iloc[:,20], color=\"green\")\n",
    "plot = defunciones_plot + ventiladores_plot\n",
    "ax8.legend(plot, [\"Defunciones nacionales\", \"Defunciones regionales\", \"Ventiladores ocupados\"], fontsize=15)\n",
    "plt.ylabel(\"Cantidad ventiladores\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de variables\n",
    "### Se eliminan variables con datos faltantes incluso después de la interpolación.\n",
    "Candidatos: \n",
    " - Pacientes críticos\n",
    " - Defunciones nacional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(labels=[\"Pac. criticos nacional\", \"Defunciones nacional\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisando que no queden datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización y análisis de correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "corr = data.corr(method=\"pearson\")\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(corr,cmap='coolwarm', vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,len(data.columns),1)\n",
    "ax.set_xticks(ticks)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(data.columns)\n",
    "ax.set_yticklabels(data.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pacientes críticos acumulados a diarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defunc_ix = list(data.columns).index(\"Defunciones regional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X = data.copy()\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X, columns=data.columns, index=data.index)\n",
    "\n",
    "ind = int(X.shape[0]*0.7)\n",
    "ind_name = data.index[ind]\n",
    "ind_name_nxt = data.index[ind+1]\n",
    "#y_index = list(data.columns).index(\"Camas UCI ocupadas COVID-19\")\n",
    "\n",
    "y_lab = \"Camas UCI nac.\"\n",
    "\n",
    "X_train = X.loc[:ind_name, X.columns != y_lab]\n",
    "X_test = X.loc[ind_name_nxt:, X.columns != y_lab]\n",
    "y_train = X.loc[:ind_name, \"Camas UCI nac.\"]\n",
    "y_test = X.loc[ind_name_nxt:, \"Camas UCI nac.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#defunc_ix, bedrooms_ix, population_ix, household_ix = [\n",
    "#    list(housing.columns).index(col)\n",
    "#    for col in (\"total_rooms\", \"total_bedrooms\", \"population\", \"households\")]\n",
    "defunc_ix = list(X_train.columns).index(\"Defunciones regional\")\n",
    "# = data.iloc[:, defunc_ix]\n",
    "class DataFormatter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kwargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def acum_to_daily(self, X, y=None):\n",
    "        temp_defunc = X[:, defunc_ix]\n",
    "        defunc_diario = [temp_defunc[i] - temp_defunc[i-1] for i in range(X.shape[0]-1,0,-1)]\n",
    "        defunc_diario = np.flip(defunc_diario).tolist()\n",
    "        defunc_diario[0] = 0\n",
    "        defunc_diario.append(temp_defunc[X.shape[0]-1])\n",
    "        X[:,defunc_ix] = defunc_diario\n",
    "        return X\n",
    "        #return np.c_[X, defunc_diario]\n",
    "    def scale_data(self, X, y=None):\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        data_scaled = scaler.fit_transform(X)\n",
    "        return data_scaled\n",
    "\n",
    "formatter = DataFormatter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prec_train = formatter.acum_to_daily(X_train.values)\n",
    "data_prec_test = formatter.acum_to_daily(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_prec_train_norm = formatter.scale_data(data_prec_train)\n",
    "#data_prec_test_norm = formatter.scale_data(data_prec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(\n",
    "    data=data_prec_train,\n",
    "    columns=list(X_train.columns),\n",
    "    index=X_train.index)\n",
    "\n",
    "x_test = pd.DataFrame(\n",
    "    data=data_prec_test,\n",
    "    columns=list(X_test.columns),\n",
    "    index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminación de variables por importancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "})\n",
    "importances = importances.sort_values(by='Importance', ascending=False)\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTE\n",
    "x_train2 = x_train.drop([\"Segunda_V\", \"Enfermedad hepática crónica\", \"Enfermedad neurológica crónica\",\"Enfermedad renal crónica\",\"Cardiopatía crónica\",\"Enfermedad pulmonar crónica\",\"Enfermedad cardiovascular\",\"Asma\",\"Obesidad\",\"Diabetes\",\"V_Unica\"], axis=1)\n",
    "x_test2 = x_test.drop([\"Segunda_V\", \"Enfermedad hepática crónica\", \"Enfermedad neurológica crónica\",\"Enfermedad renal crónica\",\"Cardiopatía crónica\",\"Enfermedad pulmonar crónica\",\"Enfermedad cardiovascular\",\"Asma\",\"Obesidad\",\"Diabetes\",\"V_Unica\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(x_train2, y_train)\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': x_train2.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "})\n",
    "importances = importances.sort_values(by='Importance', ascending=False)\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer plot de importancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar variables correlacionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = x_train2.corr(method=\"pearson\")\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "cor_matrix = corr.abs()\n",
    "upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(np.bool))\n",
    "#upper_tri.iloc[4,:] > 0.90\n",
    "#print(upper_tri)\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.90)]\n",
    "print(to_drop)\n",
    "\n",
    "#data_dropped = x_train.copy()\n",
    "#data_dropped = data_dropped.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTE\n",
    "i=0\n",
    "j=0\n",
    "corrList = []\n",
    "corr2 = corr.index[np.where((corr.iloc[:,0] >= 0.90) & (corr.iloc[:,0] != 1))]\n",
    "while(i < len(corr.columns)):\n",
    "    while(j < len(corr2)):\n",
    "        corrList.append(corr.index[np.where((corr.iloc[:,0] >= 0.90) & (corr.iloc[:,0] != 1))][j])\n",
    "        j=j+1\n",
    "    \n",
    "    x_train2 = x_train2.drop(corrList, axis=1)\n",
    "    x_test2 = x_test2.drop(corrList, axis=1)\n",
    "    corr = x_train2.corr(method=\"pearson\")\n",
    "    i=i+1\n",
    "    j=0\n",
    "    corrList = []\n",
    "    corr2 = corr.index[np.where((corr.iloc[:,0] >= 0.90) & (corr.iloc[:,0] != 1))]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTE\n",
    "x_train3 = x_train2\n",
    "x_test3 = x_test2\n",
    "corr = x_train3.corr(method=\"pearson\")\n",
    "corr\n",
    "\n",
    "#### ¿POR QUÉ NO SE ELIMINA HIPERTENSIÓN ARTERIAL/INMUNOCOMPROMETIDO Y VENT.DISP/TOTAL.VENT#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTE\n",
    "#x_train3 = x_train2.drop([\"Hipertensión arterial\", \"Camas UTI nac.\", \"Camas UCI ocupadas COVID-19\", \"Camas UCI habilitadas\", 'Camas medias nac.', 'Vent. disponibles', 'Casos activos region'], axis=1)\n",
    "#x_test3 = x_test2.drop([\"Hipertensión arterial\", \"Camas UTI nac.\", \"Camas UCI ocupadas COVID-19\", \"Camas UCI habilitadas\", 'Camas medias nac.', 'Vent. disponibles', 'Casos activos region'], axis=1)\n",
    "#corr = x_train3.corr(method=\"pearson\")\n",
    "#corr\n",
    "#to_drop = x_train[[\"Enfermedad renal crónica\", \"Camas UCI nac.\", ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train3, y_train)\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': x_train3.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "})\n",
    "importances = importances.sort_values(by='Importance', ascending=False)\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train3.copy()\n",
    "x_test = x_test3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.merge(x_train, y_train, how='outer',left_index=True, right_index=True)\n",
    "x_test = pd.merge(x_test, y_test, how='outer',left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "#test_size = round(0.25*data.shape[0])\n",
    "#print(test_size)\n",
    "#data_x = data.drop(\"Camas UCI ocupadas COVID-19\", axis=1)\n",
    "#data_y = data[\"Camas UCI ocupadas COVID-19\"].copy()\n",
    "#split = TimeSeriesSplit(data_x, data_y, test_size=test_size)\n",
    "#for train_index, test_index in TimeSeriesSplit.split(data_x):\n",
    "#    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#    X_train, X_test = X[train_index], X[test_index]\n",
    "#    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = strat_train_set.drop(\"Camas UCI ocupadas COVID-19\", axis=1)\n",
    "#uci = strat_train_set[\"Camas UCI ocupadas COVID-19\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predct = lin_reg.predict(x_test3)\n",
    "print(\"Predictions:\", linear_predct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predct = pd.Series(linear_predct)\n",
    "linear_predct.index = x_test3.index\n",
    "\n",
    "#print(y_test)\n",
    "#print(linear_predct.index)\n",
    "y_test.corr(linear_predct)\n",
    "\n",
    "data_linear = pd.concat([y_test, linear_predct], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax4 = plt.subplots(1, 1)\n",
    "ax4.plot(data_linear)\n",
    "ax4.legend(('Valores referencia', 'Valores predichos'), fontsize=15)\n",
    "plt.title(\"Predicción Regresión Lineal\", fontsize=30)\n",
    "plt.xlabel(\"Fecha\", fontsize=16)\n",
    "plt.ylabel(\"UCI ocupadas\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lin_mse = mean_squared_error(y_test, linear_predct)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "lin_mae = mean_absolute_error(y_test, linear_predct)\n",
    "lin_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_predictions = tree_reg.predict(x_test)\n",
    "tree_mse = mean_squared_error(y_test, tree_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the data set\n",
    "# Equation f(yt) = f(yt-1)\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(name, dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    names = [(name + \"_t-\" + str(i)) for i in range(look_back)]\n",
    "    names.reverse()\n",
    "    dt = dataset.values\n",
    "    for i in range(len(dt)-look_back-1):\n",
    "        a = dt[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dt[i + look_back])\n",
    "    indices = dataset.index[(look_back+1):]\n",
    "    dataset_ret = pd.DataFrame(dataX, columns=names, index=indices)\n",
    "    return dataset_ret#np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Insertar retardos en dataset de features train\n",
    "dt_train = pd.DataFrame()\n",
    "for col in x_train.columns:\n",
    "    var = x_train[col]\n",
    "    var_ret = create_dataset(col, var, look_back)\n",
    "    selected_cols = var_ret.columns[:-1] # Remove Xt-0\n",
    "    var_ret = var_ret[selected_cols]\n",
    "    dt_train[selected_cols] = var_ret\n",
    "x_train = pd.DataFrame(dt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insertar retardos en dataset de features test\n",
    "dt_test = pd.DataFrame()\n",
    "for col in x_test.columns:\n",
    "    var = x_test[col]\n",
    "    var_ret = create_dataset(col, var, look_back)\n",
    "    selected_cols = var_ret.columns[:-1] # Remove Xt-0\n",
    "    var_ret = var_ret[selected_cols]\n",
    "    dt_test[selected_cols] = var_ret\n",
    "x_test = pd.DataFrame(dt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insertar retardos en dataset de features test\n",
    "y_lab_t0 = y_lab + \"_t-0\"\n",
    "\n",
    "y_train = create_dataset(y_lab, y_train, look_back)\n",
    "y_train = y_train[[y_lab_t0]]\n",
    "y_test = create_dataset(y_lab, y_test, look_back)\n",
    "y_test = y_test[[y_lab_t0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicar Multilayer Perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit Multilayer Perceptron model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "# Estimate model performance\n",
    "trainScore = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore, sqrt(trainScore)))\n",
    "testScore = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore, sqrt(testScore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for training\n",
    "trainPredict = model.predict(x_train)\n",
    "testPredict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(data[[y_lab]])\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(data[[y_lab]])\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(data)-1, :] = testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredictPlot = pd.DataFrame(trainPredictPlot, index=data.index)\n",
    "testPredictPlot = pd.DataFrame(testPredictPlot, index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot original data and predictions\n",
    "fig, ax = plt.subplots(figsize=(18,8)) # Tamaño del gráfico\n",
    "plt.plot(X[[y_lab]], color=\"blue\", label=\"Original data\")\n",
    "\n",
    "#Título del gráfico\n",
    "ax.set_title('Predicción del número de camas UCI nacional')\n",
    "\n",
    "# Define del eje y\n",
    "ax.set_ylabel('Camas UCI')\n",
    "plt.grid(True, 'major', 'y', ls='--', lw=1.5, c='k', alpha=.3)\n",
    "\n",
    "#Define el eje x\n",
    "plt.tick_params(axis='x', which='major', labelsize=12)\n",
    "\n",
    "#plt.axis([0, 155,0,650])\n",
    "\n",
    "plt.plot(trainPredictPlot, color=\"green\", label=\"Train predict\")\n",
    "plt.plot(testPredictPlot, color=\"orange\", label=\"Test predict\")\n",
    "ax.legend(loc=\"lower right\", title=\"\", frameon=False)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_temp = x_train\n",
    "x_test_temp = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features !=columnas]\n",
    "features = round(x_train_temp.shape[1]/(look_back-1))\n",
    "x_train_temp = np.reshape(x_train_temp.values, (x_train_temp.shape[0], features, look_back-1))\n",
    "x_test_temp = np.reshape(x_test_temp.values, (x_test_temp.shape[0], features, look_back-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "batch_size = 1\n",
    "look_forward = 14\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, batch_input_shape=(batch_size, features, look_back-1), stateful=True, return_sequences=True))\n",
    "model.add(LSTM(4, batch_input_shape=(batch_size, features, look_back-1), stateful=True))\n",
    "model.add(Dense(look_forward))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_temp = y_train\n",
    "y_test_temp = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    model.fit(x_train_temp, y_train_temp.values, epochs=1, batch_size=batch_size, verbose=2, shuffle=False)\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(x_train_temp, batch_size=batch_size)\n",
    "model.reset_states()\n",
    "testPredict = model.predict(x_test_temp, batch_size=batch_size)\n",
    "# invert predictions\n",
    "#trainPredict = scaler.inverse_transform(trainPredict)\n",
    "#y_train = scaler.inverse_transform([y_train])\n",
    "#testPredict = scaler.inverse_transform(testPredict)\n",
    "#y_test = scaler.inverse_transform([y_test])\n",
    "# calculate root mean squared error\n",
    "trainScore = sqrt(mean_squared_error(y_train_temp.values[:,0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = sqrt(mean_squared_error(y_test_temp.values[:,0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainPredict_temp = trainPredict\n",
    "#testPredict_temp = testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = trainPredict[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#today = testPredict.shape[0]\n",
    "testPredictActual = testPredict[:,0]\n",
    "testPredictFuture = testPredict[-1,0:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "Y = X[[y_lab]]\n",
    "last_date = data.index[-1]\n",
    "predicted_dates = pd.date_range(start = last_date, periods = 14).to_pydatetime().tolist()\n",
    "Y = Y.reindex(Y.index.union(predicted_dates))\n",
    "#new_len = len(trainPredict) + len(predicted_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "# Create datasets for plotting\n",
    "base = np.empty_like(Y)\n",
    "base[:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reference data\n",
    "referencePlot = deepcopy(base[:])\n",
    "referencePlot[:len(X),:] = X[[y_lab]]\n",
    "referencePlot = pd.DataFrame(referencePlot, columns=['Reference values'], index=Y.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train predict data\n",
    "trainPredictPlot = deepcopy(base[:])\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back,0] = trainPredict[:]\n",
    "trainPredictPlot = pd.DataFrame(trainPredictPlot, columns=['Predicted Training'], index=Y.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test predict data\n",
    "testPredictPlot = deepcopy(base[:])\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(base)-len(testPredictFuture),0] = testPredictActual[:]\n",
    "testPredictPlot = pd.DataFrame(testPredictPlot, columns=['Predicted Testing'], index=Y.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predicted data\n",
    "predictedFuturePlot = deepcopy(base[:])\n",
    "predictedFuturePlot[len(base)-len(testPredictFuture):,0] = testPredictFuture[:]\n",
    "predictedFuturePlot = pd.DataFrame(predictedFuturePlot, columns=['Predicted Future'],index=Y.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData = pd.merge(referencePlot, trainPredictPlot, how='outer', left_index=True, right_index=True)\n",
    "plotData = pd.merge(plotData, testPredictPlot, how='outer', left_index=True, right_index=True)\n",
    "plotData = pd.merge(plotData, predictedFuturePlot, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " fig = plt.figure(figsize=(18,8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(plotData)\n",
    "#Título del gráfico\n",
    "plt.title('Red Neuronal LSTM2', fontsize=30)\n",
    "plt.xlabel(\"Fecha\", fontsize=16)\n",
    "plt.ylabel(\"Camas UCI Normalizado\", fontsize=16)\n",
    "ax.grid(True, 'major', 'y', ls='--', lw=1.5, c='k', alpha=.3)\n",
    "ax.legend(plotData.columns,loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
